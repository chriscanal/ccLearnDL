{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 650M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before\n",
      "(60000, 28, 28)\n",
      "shape after\n",
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "im_width  = X_train.shape[1]\n",
    "im_height = X_train.shape[2]\n",
    "print('shape before')\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(num_train,1, im_width,im_height)\n",
    "X_test = X_test.reshape(num_test,1, im_width,im_height)\n",
    "\n",
    "print('shape after')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove numbers 5 through 9\n",
    "newX = []\n",
    "newy = []\n",
    "newXtest = []\n",
    "newYtest = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] < 5:\n",
    "        newX.append(X_train[i])\n",
    "        newy.append(y_train[i])\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] < 5: \n",
    "        newXtest.append(X_test[i])\n",
    "        newYtest.append(y_test[i])\n",
    "X_train = np.array(newX)\n",
    "y_train = np.array(newy)\n",
    "X_test = np.array(newXtest)\n",
    "y_test = np.array(newYtest)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum of X_train: 255.0\n",
      "maximum of X_train: 1.0\n"
     ]
    }
   ],
   "source": [
    "# change type to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize the range\n",
    "print('maximum of X_train:',np.max(X_train[:]))\n",
    "X_train /= 255.0;\n",
    "X_test /= 255.0;\n",
    "print('maximum of X_train:',np.max(X_train[:]))\n",
    "\n",
    "# convert class vectors to binary class matrices (one hot representation)\n",
    "nb_classes = np.unique(y_train).size\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 64, 28, 28)  6464        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 64, 28, 28)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 64, 28, 28)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 16, 28, 28)  4112        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 16, 28, 28)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 16, 28, 28)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 16, 14, 14)  0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 3136)        0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 100)         313700      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 100)         0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                (None, 100)         0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 5)           505         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 5)           0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 324781\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# construct the network\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 10, 10, border_mode='same', input_shape=(1,im_width,im_height)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.23))\n",
    "model.add(Convolution2D(16, 2, 2, border_mode='same', input_shape=(1,im_width,im_height)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.23))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.23))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/5\n",
      "30596/30596 [==============================] - 48s - loss: 0.1343 - acc: 0.9573 - val_loss: 0.0509 - val_acc: 0.9918\n",
      "Epoch 2/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0292 - acc: 0.9913 - val_loss: 0.0105 - val_acc: 0.9961\n",
      "Epoch 3/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0088 - val_acc: 0.9984\n",
      "Epoch 4/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0048 - val_acc: 0.9992\n",
      "Epoch 5/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0199 - val_acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "start = time.time()\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:    0.0198585593819\n",
      "Test accuracy: 0.99299474606\n",
      "Time elapsed:  259.2973699569702 seconds\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print ('Test score:   ', score[0])\n",
    "print( 'Test accuracy:', score[1])\n",
    "print( 'Time elapsed: ',(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x11a9dc898>\n"
     ]
    }
   ],
   "source": [
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x134759e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGgAAAEACAYAAABfzDMiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCqwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134768400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('model.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2433"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the weights of the model\n",
    "model.save_weights('modelWeights.h5',overwrite=True)\n",
    "\n",
    "#Save the architecture of the model\n",
    "json_string_modelArchitecture = model.to_json()\n",
    "open('my_model_architecture.json', 'w').write(json_string_modelArchitecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'model' in dir():\n",
    "    print (\"deleted model\")\n",
    "    del model\n",
    "else:\n",
    "    print (\"deleted already\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the old architecture\n",
    "model = model_from_json(open('my_model_architecture.json').read())\n",
    "model.load_weights('modelWeights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 64, 28, 28)  6464        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 64, 28, 28)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 64, 28, 28)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 16, 28, 28)  4112        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 16, 28, 28)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 16, 28, 28)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 16, 14, 14)  0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 3136)        0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 100)         313700      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 100)         0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                (None, 100)         0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 5)           505         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 5)           0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 324781\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Show the model to make sure the load in worked\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 64, 28, 28)  6464        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 64, 28, 28)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 64, 28, 28)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 16, 28, 28)  4112        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 16, 28, 28)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 16, 28, 28)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 16, 14, 14)  0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 3136)        0           maxpooling2d_1[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 10576\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#pop the classification layers\n",
    "model.layers.pop() #remove softmax activation\n",
    "model.layers.pop() #remove classification output layer\n",
    "model.layers.pop() #remove dropout\n",
    "model.layers.pop() #remove Relu Activation\n",
    "model.layers.pop() #remove fully connected layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing  convolution2d_1\n",
      "Freezing  activation_1\n",
      "Freezing  dropout_1\n",
      "Freezing  convolution2d_2\n",
      "Freezing  activation_2\n",
      "Freezing  dropout_2\n",
      "Freezing  maxpooling2d_1\n",
      "Freezing  flatten_1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].train=False\n",
    "    print (\"Freezing \", model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 64, 28, 28)  6464        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 64, 28, 28)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 64, 28, 28)  0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 16, 28, 28)  4112        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 16, 28, 28)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 16, 28, 28)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 16, 14, 14)  0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 3136)        0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                    (None, 100)         600         activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)          (None, 100)         0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)                (None, 100)         0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                    (None, 5)           505         dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)          (None, 5)           0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 11681\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.23))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile the new model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/5\n",
      "30596/30596 [==============================] - 48s - loss: 0.5108 - acc: 0.9609 - val_loss: 0.0258 - val_acc: 0.9977\n",
      "Epoch 2/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0190 - acc: 0.9969 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 3/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0136 - acc: 0.9972 - val_loss: 0.0066 - val_acc: 0.9982\n",
      "Epoch 4/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 5/5\n",
      "30596/30596 [==============================] - 47s - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0064 - val_acc: 0.9979\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before\n",
      "(60000, 28, 28)\n",
      "shape after\n",
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "im_width  = X_train.shape[1]\n",
    "im_height = X_train.shape[2]\n",
    "print('shape before')\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(num_train,1, im_width,im_height)\n",
    "X_test = X_test.reshape(num_test,1, im_width,im_height)\n",
    "\n",
    "print('shape after')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum of X_train: 255.0\n",
      "maximum of X_train: 1.0\n"
     ]
    }
   ],
   "source": [
    "# change type to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize the range\n",
    "print('maximum of X_train:',np.max(X_train[:]))\n",
    "X_train /= 255.0;\n",
    "X_test /= 255.0;\n",
    "print('maximum of X_train:',np.max(X_train[:]))\n",
    "\n",
    "# convert class vectors to binary class matrices (one hot representation)\n",
    "nb_classes = np.unique(y_train).size\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "A target array with shape (60000, 10) was passed for an output of shape (None, 5) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7825941cdb00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit(X_train, Y_train,\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     verbose=1, validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/caglayan/anaconda/envs/deeplearn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/caglayan/anaconda/envs/deeplearn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# prepare input arrays and training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/caglayan/anaconda/envs/deeplearn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    890\u001b[0m                           in zip(y, sample_weights, class_weights, self.sample_weight_modes)]\n\u001b[1;32m    891\u001b[0m         \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mcheck_loss_and_target_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_output_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/caglayan/anaconda/envs/deeplearn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, losses, output_shapes)\u001b[0m\n\u001b[1;32m    199\u001b[0m                 raise Exception('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    200\u001b[0m                                 \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                                 \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                                 \u001b[0;34m'This loss expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                                 \u001b[0;34m'targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: A target array with shape (60000, 10) was passed for an output of shape (None, 5) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "start = time.time()\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print ('Test score:   ', score[0])\n",
    "print( 'Test accuracy:', score[1])\n",
    "print( 'Time elapsed: ',(end - start), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
